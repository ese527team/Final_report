{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3760,
     "status": "ok",
     "timestamp": 1647619976701,
     "user": {
      "displayName": "RuoYu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghpzy47X5TYfuqSiIYeU2NoI9KwyW4BT6-_TBNQ=s64",
      "userId": "03944796655307268336"
     },
     "user_tz": 300
    },
    "id": "Kr5LC3S-u96b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot as plt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import matplotlib.pyplot as plt\n",
    "from fitter import Fitter, get_common_distributions, get_distributions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.datasets import fetch_species_distributions, load_digits\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, train_test_split\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.decomposition as dp\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoLarsIC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow.keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2628,
     "status": "ok",
     "timestamp": 1647619990682,
     "user": {
      "displayName": "RuoYu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghpzy47X5TYfuqSiIYeU2NoI9KwyW4BT6-_TBNQ=s64",
      "userId": "03944796655307268336"
     },
     "user_tz": 300
    },
    "id": "YFqjk9L5VJTo",
    "outputId": "a01e4e46-02d1-4c89-fca5-cad26de4b67e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JanRuoYu\\AppData\\Local\\Temp\\ipykernel_7428\\4155429469.py:1: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  data = pd.read_csv(\"data_AP.csv\",dtype={'Symbol': np.str},parse_dates=['Accper'])\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_AP.csv\",dtype={'Symbol': np.str},parse_dates=['Accper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier25=data.iloc[:,-1].quantile(0.25)\n",
    "tier75=data.iloc[:,-1].quantile(0.75)\n",
    "data['classification']=0\n",
    "for i in range(0,len(data.iloc[:,-1])):\n",
    "    if (data.iloc[i,-2]<=tier25):\n",
    "        data.iloc[i,-1]=-1\n",
    "    elif (data.iloc[i,-2]>=tier75):\n",
    "        data.iloc[i,-1]=1\n",
    "    else:\n",
    "        data.iloc[i,-1]=0\n",
    "data\n",
    "data['classification']=data['classification'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stkcd</th>\n",
       "      <th>Accper</th>\n",
       "      <th>Current_Ratio</th>\n",
       "      <th>Liquidity_Ratio</th>\n",
       "      <th>Cash_Ratio</th>\n",
       "      <th>Cash_Flow_Interest_Coverage_Ratio</th>\n",
       "      <th>Asset-liability_Ratio</th>\n",
       "      <th>Equity_Ratio</th>\n",
       "      <th>Total_Assets_Growth_Rate</th>\n",
       "      <th>Net_Profit_Growth_Rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Return_On_Assets</th>\n",
       "      <th>Return_On_Net_Assets</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>Operating_Profit_Margin</th>\n",
       "      <th>Cost_Profit_Margin</th>\n",
       "      <th>Cash-To-Profit_Ratio</th>\n",
       "      <th>Return_On_Investment</th>\n",
       "      <th>EPS</th>\n",
       "      <th>Future_EPS</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0055.HK</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>1.042785</td>\n",
       "      <td>0.577486</td>\n",
       "      <td>0.163058</td>\n",
       "      <td>19.986092</td>\n",
       "      <td>0.270758</td>\n",
       "      <td>0.371286</td>\n",
       "      <td>-0.005702</td>\n",
       "      <td>0.100264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021926</td>\n",
       "      <td>0.020527</td>\n",
       "      <td>1.380945e+08</td>\n",
       "      <td>0.071808</td>\n",
       "      <td>0.079216</td>\n",
       "      <td>0.656901</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.050030</td>\n",
       "      <td>0.092089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0055.HK</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>1.028640</td>\n",
       "      <td>0.607188</td>\n",
       "      <td>0.197985</td>\n",
       "      <td>365.451594</td>\n",
       "      <td>0.269749</td>\n",
       "      <td>0.369392</td>\n",
       "      <td>0.019587</td>\n",
       "      <td>0.243492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055420</td>\n",
       "      <td>0.053246</td>\n",
       "      <td>3.517456e+08</td>\n",
       "      <td>0.069937</td>\n",
       "      <td>0.085160</td>\n",
       "      <td>1.590517</td>\n",
       "      <td>0.014966</td>\n",
       "      <td>0.112168</td>\n",
       "      <td>0.156581</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0055.HK</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1.018991</td>\n",
       "      <td>0.630694</td>\n",
       "      <td>0.171091</td>\n",
       "      <td>204.414341</td>\n",
       "      <td>0.278266</td>\n",
       "      <td>0.385551</td>\n",
       "      <td>0.047187</td>\n",
       "      <td>0.379693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073880</td>\n",
       "      <td>0.072159</td>\n",
       "      <td>4.763158e+08</td>\n",
       "      <td>0.071424</td>\n",
       "      <td>0.085806</td>\n",
       "      <td>1.533349</td>\n",
       "      <td>0.020098</td>\n",
       "      <td>0.156581</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0055.HK</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1.035491</td>\n",
       "      <td>0.623834</td>\n",
       "      <td>0.177662</td>\n",
       "      <td>-68.529810</td>\n",
       "      <td>0.269218</td>\n",
       "      <td>0.368398</td>\n",
       "      <td>0.039166</td>\n",
       "      <td>-0.762738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005578</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>3.665077e+07</td>\n",
       "      <td>0.051783</td>\n",
       "      <td>0.074622</td>\n",
       "      <td>-6.306631</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>0.007666</td>\n",
       "      <td>0.044704</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0055.HK</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>1.022618</td>\n",
       "      <td>0.584835</td>\n",
       "      <td>0.154379</td>\n",
       "      <td>6.187099</td>\n",
       "      <td>0.257824</td>\n",
       "      <td>0.347390</td>\n",
       "      <td>0.026595</td>\n",
       "      <td>-0.402941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022913</td>\n",
       "      <td>0.023732</td>\n",
       "      <td>1.482274e+08</td>\n",
       "      <td>0.104064</td>\n",
       "      <td>0.151667</td>\n",
       "      <td>0.245828</td>\n",
       "      <td>0.019409</td>\n",
       "      <td>0.044704</td>\n",
       "      <td>0.074484</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26132</th>\n",
       "      <td>ZZ-B.ST</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>1.252963</td>\n",
       "      <td>0.967910</td>\n",
       "      <td>0.217087</td>\n",
       "      <td>-6.218580</td>\n",
       "      <td>0.636977</td>\n",
       "      <td>1.754648</td>\n",
       "      <td>0.391041</td>\n",
       "      <td>-0.524148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024385</td>\n",
       "      <td>0.026696</td>\n",
       "      <td>1.318273e+08</td>\n",
       "      <td>0.041494</td>\n",
       "      <td>0.048548</td>\n",
       "      <td>-3.275803</td>\n",
       "      <td>0.156993</td>\n",
       "      <td>0.099440</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26133</th>\n",
       "      <td>ZZ-B.ST</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>1.369232</td>\n",
       "      <td>0.936780</td>\n",
       "      <td>0.326114</td>\n",
       "      <td>2.875350</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>1.368543</td>\n",
       "      <td>0.333473</td>\n",
       "      <td>0.312685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031812</td>\n",
       "      <td>0.054694</td>\n",
       "      <td>2.142928e+08</td>\n",
       "      <td>0.164012</td>\n",
       "      <td>0.206903</td>\n",
       "      <td>0.617738</td>\n",
       "      <td>0.042299</td>\n",
       "      <td>0.236143</td>\n",
       "      <td>0.340842</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26134</th>\n",
       "      <td>ZZ-B.ST</td>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>1.425613</td>\n",
       "      <td>0.955237</td>\n",
       "      <td>0.354545</td>\n",
       "      <td>-0.779157</td>\n",
       "      <td>0.590018</td>\n",
       "      <td>1.439129</td>\n",
       "      <td>0.393759</td>\n",
       "      <td>0.371169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045464</td>\n",
       "      <td>0.076671</td>\n",
       "      <td>3.175173e+08</td>\n",
       "      <td>0.168826</td>\n",
       "      <td>0.215357</td>\n",
       "      <td>-0.196121</td>\n",
       "      <td>0.042299</td>\n",
       "      <td>0.340842</td>\n",
       "      <td>0.199575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26135</th>\n",
       "      <td>ZZ-B.ST</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1.069262</td>\n",
       "      <td>0.834902</td>\n",
       "      <td>0.094393</td>\n",
       "      <td>1.851293</td>\n",
       "      <td>0.663207</td>\n",
       "      <td>1.969187</td>\n",
       "      <td>0.157210</td>\n",
       "      <td>2.354460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051099</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>3.466858e+08</td>\n",
       "      <td>0.079311</td>\n",
       "      <td>0.149121</td>\n",
       "      <td>0.790663</td>\n",
       "      <td>0.042299</td>\n",
       "      <td>0.199575</td>\n",
       "      <td>0.017345</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26136</th>\n",
       "      <td>ZZ-B.ST</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>1.198030</td>\n",
       "      <td>1.173184</td>\n",
       "      <td>0.374820</td>\n",
       "      <td>3.295919</td>\n",
       "      <td>0.555680</td>\n",
       "      <td>1.250628</td>\n",
       "      <td>-0.018317</td>\n",
       "      <td>-0.688828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>1.089101e+08</td>\n",
       "      <td>0.109587</td>\n",
       "      <td>0.119419</td>\n",
       "      <td>3.163297</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.057053</td>\n",
       "      <td>0.130499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26137 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Stkcd     Accper  Current_Ratio  Liquidity_Ratio  Cash_Ratio  \\\n",
       "0      0055.HK 2019-03-31       1.042785         0.577486    0.163058   \n",
       "1      0055.HK 2019-09-30       1.028640         0.607188    0.197985   \n",
       "2      0055.HK 2019-12-31       1.018991         0.630694    0.171091   \n",
       "3      0055.HK 2020-03-31       1.035491         0.623834    0.177662   \n",
       "4      0055.HK 2020-06-30       1.022618         0.584835    0.154379   \n",
       "...        ...        ...            ...              ...         ...   \n",
       "26132  ZZ-B.ST 2017-12-31       1.252963         0.967910    0.217087   \n",
       "26133  ZZ-B.ST 2018-06-30       1.369232         0.936780    0.326114   \n",
       "26134  ZZ-B.ST 2018-09-30       1.425613         0.955237    0.354545   \n",
       "26135  ZZ-B.ST 2018-12-31       1.069262         0.834902    0.094393   \n",
       "26136  ZZ-B.ST 2020-06-30       1.198030         1.173184    0.374820   \n",
       "\n",
       "       Cash_Flow_Interest_Coverage_Ratio  Asset-liability_Ratio  Equity_Ratio  \\\n",
       "0                              19.986092               0.270758      0.371286   \n",
       "1                             365.451594               0.269749      0.369392   \n",
       "2                             204.414341               0.278266      0.385551   \n",
       "3                             -68.529810               0.269218      0.368398   \n",
       "4                               6.187099               0.257824      0.347390   \n",
       "...                                  ...                    ...           ...   \n",
       "26132                          -6.218580               0.636977      1.754648   \n",
       "26133                           2.875350               0.577800      1.368543   \n",
       "26134                          -0.779157               0.590018      1.439129   \n",
       "26135                           1.851293               0.663207      1.969187   \n",
       "26136                           3.295919               0.555680      1.250628   \n",
       "\n",
       "       Total_Assets_Growth_Rate  Net_Profit_Growth_Rate  ...  \\\n",
       "0                     -0.005702                0.100264  ...   \n",
       "1                      0.019587                0.243492  ...   \n",
       "2                      0.047187                0.379693  ...   \n",
       "3                      0.039166               -0.762738  ...   \n",
       "4                      0.026595               -0.402941  ...   \n",
       "...                         ...                     ...  ...   \n",
       "26132                  0.391041               -0.524148  ...   \n",
       "26133                  0.333473                0.312685  ...   \n",
       "26134                  0.393759                0.371169  ...   \n",
       "26135                  0.157210                2.354460  ...   \n",
       "26136                 -0.018317               -0.688828  ...   \n",
       "\n",
       "       Return_On_Assets  Return_On_Net_Assets          EBIT  \\\n",
       "0              0.021926              0.020527  1.380945e+08   \n",
       "1              0.055420              0.053246  3.517456e+08   \n",
       "2              0.073880              0.072159  4.763158e+08   \n",
       "3              0.005578              0.004640  3.665077e+07   \n",
       "4              0.022913              0.023732  1.482274e+08   \n",
       "...                 ...                   ...           ...   \n",
       "26132          0.024385              0.026696  1.318273e+08   \n",
       "26133          0.031812              0.054694  2.142928e+08   \n",
       "26134          0.045464              0.076671  3.175173e+08   \n",
       "26135          0.051099              0.085100  3.466858e+08   \n",
       "26136          0.012027              0.010181  1.089101e+08   \n",
       "\n",
       "       Operating_Profit_Margin  Cost_Profit_Margin  Cash-To-Profit_Ratio  \\\n",
       "0                     0.071808            0.079216              0.656901   \n",
       "1                     0.069937            0.085160              1.590517   \n",
       "2                     0.071424            0.085806              1.533349   \n",
       "3                     0.051783            0.074622             -6.306631   \n",
       "4                     0.104064            0.151667              0.245828   \n",
       "...                        ...                 ...                   ...   \n",
       "26132                 0.041494            0.048548             -3.275803   \n",
       "26133                 0.164012            0.206903              0.617738   \n",
       "26134                 0.168826            0.215357             -0.196121   \n",
       "26135                 0.079311            0.149121              0.790663   \n",
       "26136                 0.109587            0.119419              3.163297   \n",
       "\n",
       "       Return_On_Investment       EPS  Future_EPS  classification  \n",
       "0                  0.004662  0.050030    0.092089               0  \n",
       "1                  0.014966  0.112168    0.156581               0  \n",
       "2                  0.020098  0.156581    0.007666              -1  \n",
       "3                  0.012596  0.007666    0.044704              -1  \n",
       "4                  0.019409  0.044704    0.074484              -1  \n",
       "...                     ...       ...         ...             ...  \n",
       "26132              0.156993  0.099440    0.019583              -1  \n",
       "26133              0.042299  0.236143    0.340842               0  \n",
       "26134              0.042299  0.340842    0.199575               0  \n",
       "26135              0.042299  0.199575    0.017345              -1  \n",
       "26136              0.001549  0.057053    0.130499               0  \n",
       "\n",
       "[26137 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1647620311025,
     "user": {
      "displayName": "RuoYu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghpzy47X5TYfuqSiIYeU2NoI9KwyW4BT6-_TBNQ=s64",
      "userId": "03944796655307268336"
     },
     "user_tz": 300
    },
    "id": "F3qVB_EwylMx"
   },
   "outputs": [],
   "source": [
    "feature_global=data.iloc[:,2:-2]\n",
    "response_global=data.iloc[:,-2]\n",
    "response_global=response_global.values.reshape(-1,1)\n",
    "response_global_class=data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1647620336963,
     "user": {
      "displayName": "RuoYu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghpzy47X5TYfuqSiIYeU2NoI9KwyW4BT6-_TBNQ=s64",
      "userId": "03944796655307268336"
     },
     "user_tz": 300
    },
    "id": "0FLCunBmu97G"
   },
   "outputs": [],
   "source": [
    "#standard\n",
    "X_tool = StandardScaler()\n",
    "y_tool = StandardScaler()\n",
    "x_std = X_tool.fit_transform(feature_global)\n",
    "y_std = y_tool.fit_transform(response_global)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_std,y_std,test_size=0.25)\n",
    "x_train_class,x_test_class,y_train_class,y_test_class = train_test_split(x_std,response_global_class,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.1 RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41136,
     "status": "ok",
     "timestamp": 1647620385680,
     "user": {
      "displayName": "RuoYu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghpzy47X5TYfuqSiIYeU2NoI9KwyW4BT6-_TBNQ=s64",
      "userId": "03944796655307268336"
     },
     "user_tz": 300
    },
    "id": "DwcWOpGfu97I",
    "outputId": "87b8fe54-6584-4a4f-f9a7-dc56d4d5529c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rf_feature(x,y):\n",
    "    rf = RandomForestRegressor(n_jobs=10, n_estimators=500)\n",
    "    rf.fit(x, y)\n",
    "    im = rf.feature_importances_\n",
    "    FS = pd.DataFrame({\"Var\": [\"X%s\" % (i+1) for i in range(len(im))],\n",
    "                   'Name': data.columns[2:-2],\n",
    "                   \"Importance\": im})\n",
    "    FS[\"rank\"] = FS[\"Importance\"].rank(ascending=False)\n",
    "    FS = FS.sort_values(by=\"Importance\", ascending=True)\n",
    "    FS.reset_index(drop=True, inplace=True)\n",
    "    FS.to_csv(\"importance_rf.csv\", index=False)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.barh(FS.iloc[:,1],FS.iloc[:,2])\n",
    "    plt.xlabel(\"Random Forest Feature Importance\")\n",
    "    plt.savefig(\"rf_importance.png\")\n",
    "\n",
    "    feature_after_tuned=feature_global[FS[FS[\"rank\"] <= 18].Name]\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(feature_after_tuned)\n",
    "#     feature_std = scaler.transform(feature_after_tuned)\n",
    "#     feature_std=pd.DataFrame(feature_std,columns=feature_after_tuned.columns)\n",
    "\n",
    "    #select 20 important features after reduction\n",
    "    return(feature_after_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hx5dtc0PFtVG"
   },
   "source": [
    "## 2.2 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 93,
     "status": "ok",
     "timestamp": 1647621762205,
     "user": {
      "displayName": "RuoYu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghpzy47X5TYfuqSiIYeU2NoI9KwyW4BT6-_TBNQ=s64",
      "userId": "03944796655307268336"
     },
     "user_tz": 300
    },
    "id": "78sOpsD23-gu"
   },
   "outputs": [],
   "source": [
    "def pca_feature(x):\n",
    "    pca = PCA(n_components=0.85)\n",
    "    #='mle'\n",
    "    x_pca = pca.fit_transform(x)\n",
    "#     x_train_pca,x_test_pca,y_train,y_test = train_test_split(x_std_pca,y_std,test_size=0.2)\n",
    "    exp_var_pca = pca.explained_variance_ratio_\n",
    "    cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "    \n",
    "    plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "    plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal component index')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(\"pca_importance.png\")\n",
    "    \n",
    "    return(x_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_feature(x,y):\n",
    "    ###lasso regression based on AIC\n",
    "    lasso_aic = LassoLarsIC(criterion='aic', max_iter=50000)\n",
    "    lasso_aic.fit(x,y)\n",
    "    #ranks['Lasso_AIC'] = rank_to_dict(np.abs(lasso_aic.coef_), names)\n",
    "    ###lasso regression based on BIC\n",
    "    lasso_bic = LassoLarsIC(criterion='bic', max_iter=50000)\n",
    "    lasso_bic.fit(x,y)\n",
    "    #ranks['Lasso_BIC'] = rank_to_dict(np.abs(lasso_bic.coef_), names)\n",
    "    \n",
    "    bic = np.abs(lasso_bic.coef_)\n",
    "    aic = np.abs(lasso_aic.coef_)\n",
    "    mean = 1/2*(aic+bic)\n",
    "    \n",
    "    Lasso = pd.DataFrame({\"Var_bic\": [\"X%s\" % (i+1) for i in range(len(bic))],\n",
    "                          \"Var_aic\": [\"X%s\" % (i+1) for i in range(len(aic))],\n",
    "                       'Name': data.columns[2:-2],\n",
    "                       \"Importance_bic\": bic,\n",
    "                       \"Importance_aic\": aic,\n",
    "                         \"Importance_mean\": mean})\n",
    "    Lasso[\"rank\"] = Lasso[\"Importance_mean\"].rank(ascending=False)\n",
    "    Lasso = Lasso.sort_values(by=\"Importance_mean\", ascending=True)\n",
    "    Lasso.reset_index(drop=True, inplace=True)\n",
    "    Lasso.to_csv(\"importance_lasso.csv\", index=False)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.barh(Lasso.iloc[:,2],Lasso.iloc[:,5])\n",
    "    plt.xlabel(\"Lasso Regression Feature Importance\")\n",
    "    plt.savefig(\"Lasso_importance.png\")\n",
    "    \n",
    "    feature_after_tuned=feature_global[Lasso[Lasso[\"rank\"] <= 18].Name]\n",
    "    \n",
    "    #select 20 important features after reduction\n",
    "    return(feature_after_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0  5-fold cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfolds = KFold(n_splits=5,  shuffle=True)\n",
    "# x_train,x_test,y_train,y_test = train_test_split(feature_after_tuned,response_global_class,test_size=0.25)\n",
    "# x_train_1,x_train_2,y_train_1,y_train_2=train_test_split(x_train,y_train,test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIvt7HBF1slb"
   },
   "source": [
    "## 3.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(x_train,y_train,x_test,y_test):\n",
    "    Monitor=['loss']\n",
    "    MIN_delta=[0]\n",
    "    PATience=(np.linspace(start = 20, stop = 80, num = 2)).astype(int)\n",
    "    ACTivation=[\"relu\",\"tanh\"]\n",
    "    Loss=[\"mean_squared_error\"]\n",
    "    Optimizer=[\"Adam\"]\n",
    "    Acc=0\n",
    "    count=0\n",
    "    for i1 in range(0,1):\n",
    "        for i2 in range (0,1):\n",
    "            for i3 in range(0,2):\n",
    "                for i4 in range(0,2):\n",
    "                    for i5 in range(0,1):\n",
    "                        for i6 in range(0,2):\n",
    "                            for train, test in kfolds.split(x_train, y_train):\n",
    "                                # 定义神经网络模型中的eaylu stop 如果测试集误差连续patienc次不再下降 则返回测试集对应的最佳模型 restore_best_weights 返回最佳\n",
    "                                early_stopping = tf.keras.callbacks.EarlyStopping(monitor=Monitor[i1],min_delta=MIN_delta[i2], patience=PATience[i3], restore_best_weights=True)\n",
    "                                # 定义lstm模型\n",
    "                                model = tf.keras.Sequential([\n",
    "                                    # 变成n*1序列\n",
    "                                    tf.keras.layers.Reshape((x_train.shape[1], 1), input_shape=(x_train.shape[1],)),\n",
    "                                    # lstm\n",
    "                                    tf.keras.layers.LSTM(64, activation=ACTivation[i4], input_shape=(x_train.shape[1], 1)),\n",
    "                                    # dropout 增加泛化能力\n",
    "                                    tf.keras.layers.Dropout(0.2),\n",
    "                                    # 输出层\n",
    "                                    tf.keras.layers.Dense(1)\n",
    "                                ])\n",
    "                                # optimizer 优化器 求解算法 比如sgd是梯度下降 这个是nadam是sgd的改进\n",
    "                                # loss 损失函数\n",
    "                                model.compile(optimizer=Optimizer[i6], loss=Loss[i5])\n",
    "                                # validation data 验证集\n",
    "                                # epochs 迭代次数\n",
    "                                # barch size 批次数量 每次更新模型参数的样本数量\n",
    "                                # use_multiprocessing 多线程计算加快计算速度\n",
    "                                history = model.fit(x_train, y_train,\n",
    "                                                    epochs=2000,\n",
    "                                                    verbose=0, # 0不查看迭代过程 可取0 1 2\n",
    "                                                    batch_size=32,\n",
    "                                                    use_multiprocessing=True,\n",
    "                                                    callbacks=[early_stopping])\n",
    "                                scores = model.evaluate(x_test,y_test, verbose=0)\n",
    "                                count=count+1\n",
    "                                print(\"currently in LSTM iteration \"+str(count)+\" out of 36\")\n",
    "\n",
    "                                if (scores>Acc):\n",
    "                                    Acc=scores\n",
    "                                    Mon=Monitor[i1]\n",
    "                                    MIN=MIN_delta[i2]\n",
    "                                    PAT=PATience[i3]\n",
    "                                    ACT=ACTivation[i4]\n",
    "                                    Opt=Optimizer[i6]\n",
    "                                    LOSS=Loss[i5]\n",
    "\n",
    "\n",
    "    print(\"The best hyper-parameter of is: The monitor is \"+Monitor[i1]+\" and MIN_delta[i2] is set to \"+str(MIN_delta[i2]))\n",
    "    print(\"The PAT is \"+str(PAT)+\" and ACT is set to \"+ACT+\" and OPT is \"+Opt+\" and loss function is \"+LOSS)\n",
    "    print(\"The accuracy in tuning is:\",Acc)\n",
    "\n",
    "    tier25_lstm=data.iloc[:,-1].quantile(0.25)\n",
    "    tier75_lstm=data.iloc[:,-1].quantile(0.75)\n",
    "    y_pred=model.predict(x_test)\n",
    "    count=0\n",
    "    for i in len(y_pred):\n",
    "        if (y_pred[i]<=tier25_lstm):\n",
    "            y_pred[i]=-1\n",
    "            if (y_pred[i]==y_test[i]):\n",
    "                count=count+1\n",
    "        elif (y_pred[i]>=tier75_lstm):\n",
    "            y_pred[i]=1\n",
    "            if (y_pred[i]==y_test[i]):\n",
    "                count=count+1\n",
    "        else:\n",
    "            y_pred[i]=0\n",
    "            if (y_pred[i]==y_test[i]):\n",
    "                count=count+1\n",
    "\n",
    "    Acc_pred_lstm=count/len(y_pred)\n",
    "    print(\"The accuracy of prediction using lstm is:\"+str(Acc_pred_lstm))\n",
    "    return(y_pred,Acc_pred_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ob466k14oi9"
   },
   "source": [
    "## 3.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(x_large_train,y_large_train,x_train,y_train,x_test,y_test):\n",
    "    # Tune for SVM\n",
    "    print(\"Here is the tuning for SVM\")\n",
    "    print(\"Tolerance is for tolearance of maximum error in fitting, and Penalty is for penalty parameter\")\n",
    "\n",
    "\n",
    "    Kernel=['poly','linear','rbf']\n",
    "    Tol=[10e-4,10e-5,10e-6,10e-7,10e-8]\n",
    "    c=np.linspace(start = 5, stop = 10, num = 5)\n",
    "    Acc=0\n",
    "\n",
    "    count=0\n",
    "    p3d = pd.DataFrame(columns=['Param 1','Param 2','Response Value']) \n",
    "    ##################\n",
    "\n",
    "    for j in range(0,3):\n",
    "        for k in range(0,5):\n",
    "            for m in range(0,5):\n",
    "                SVM=OneVsRestClassifier(svm.SVC(kernel=Kernel[j],tol=Tol[k],C=c[m]))\n",
    "                scores = cross_val_score(SVM,x_train, y_train, scoring='accuracy', cv=kfolds, n_jobs=-1)\n",
    "                #############\n",
    "                p3d.loc[count]=[Tol[k],c[m],scores.mean()]\n",
    "                count=count+1\n",
    "                print(\"currently in SVM iteration \"+str(count)+\" out of 75\")\n",
    "                ###################\n",
    "                if (scores.mean()>Acc):\n",
    "                    Acc=scores.mean()\n",
    "                    KERNEL=Kernel[j]\n",
    "                    Tolerance=Tol[k]\n",
    "                    Penalty=c[m]\n",
    "\n",
    "\n",
    "    for dist in range (0,3):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.gca(projection='3d')\n",
    "        ax.plot_trisurf(p3d['Param 1'], p3d['Param 2'], p3d['Response Value'], cmap=plt.cm.viridis, linewidth=0.2)\n",
    "        ax.set_xlabel('Param 1')\n",
    "        ax.set_ylabel('Param 2')\n",
    "        ax.set_zlabel('Response Value')\n",
    "        ax.set_title(\"SVM with Kernel \"+Kernel[dist])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    print(\"The best hyper-parameter of pair \"+str(i+1)+\" is: KERNEL = \"+KERNEL+\",  Tolerance = \"+str(Tolerance)+\", and Penalty = \"+str(Penalty))\n",
    "    print(\"The corresponding accuracy in tunning for svm is \"+str(Acc))\n",
    "\n",
    "    SVM_pred = OneVsRestClassifie(svm.SVC(kernel=KERNEL,tol=Tolerance,C=Penalty))\n",
    "    SVM_pred.fit(x_large_train,y_large_train)\n",
    "    Acc_pred=SVM_pred.score(x_test,y_test)\n",
    "    print(\"The corresponding accuracy in prediction for SVM is \"+str(Acc_pred))\n",
    "    y_pred_SVM=SVM_pred.predict(x_test)\n",
    "    return (y_pred_SVM,Acc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(x_train,y_train,x_test,y_test):\n",
    "    parameter_space = {\n",
    "        'hidden_layer_sizes': [(56,28,28,56),(120,60,30,60,120),(120,60,120)],\n",
    "        'activation': ['tanh'],\n",
    "        'solver': ['adam'],\n",
    "        'alpha': [0.01],\n",
    "        'batch_size':['auto'],\n",
    "        'learning_rate': ['adaptive'],\n",
    "        \"max_iter\": [5000],\n",
    "        'early_stopping':[True],\n",
    "        'n_iter_no_change':[1000],\n",
    "        'tol':[10e-5],\n",
    "        'verbose':[True]\n",
    "    }\n",
    "    mlp = MLPClassifier()\n",
    "    estimator = GridSearchCV(mlp, parameter_space, n_jobs=-1,cv=3,scoring='accuracy')\n",
    "    estimator.fit(x_train.values,y_train)\n",
    "    y_pred =estimator.predict(x_test.values)\n",
    "    print(\"best estimator\",estimator.best_params_)\n",
    "    Acc_pred_MLP=estimator.score(x_test, y_test)\n",
    "    print(\"The predicted accuracy for MLP is: \"+str(Acc_pred_MLP))\n",
    "    return(y_pred,Acc_pred_MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JanRuoYu\\AppData\\Local\\Temp\\ipykernel_29768\\457348620.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf.fit(x, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is: Random_forest+LSTM\n"
     ]
    }
   ],
   "source": [
    "feature_selection=['Random_forest','PCA','Lasso']\n",
    "Model_selection=['KNN','LSTM','SVM','MLP']\n",
    "for i in range(0,3):\n",
    "    if (i==0):\n",
    "        feature_after_tuned=rf_feature(feature_global.values,response_global)\n",
    "    if (i==1):\n",
    "        feature_after_tuned=pca_feature(feature_global.values,response_global)\n",
    "    if (i==2):\n",
    "        feature_after_tuned=lasso_feature(feature_global.values,response_global)\n",
    "        \n",
    "        \n",
    "\n",
    "    kfolds = KFold(n_splits=5,  shuffle=True)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(feature_after_tuned,response_global_class,test_size=0.2)\n",
    "    x_train_1,x_train_2,y_train_1,y_train_2=train_test_split(x_train,y_train,test_size=0.3)\n",
    "    y_pred = pd.DataFrame(columns=[]) \n",
    "    for j in range(1,2):\n",
    "        if (j==0):\n",
    "            print(\"The model is: \"+feature_selection[i]+\"+\"+Model_selection[j])\n",
    "            pred,Acc= KNN(x_train,y_train,x_train_2,y_train_2,x_test,y_test)\n",
    "            y_pred.insert(y_pred.shape[1],feature_selection[i]+Model_selection[j], pred)\n",
    "        if (j==1):\n",
    "            print(\"The model is: \"+feature_selection[i]+\"+\"+Model_selection[j])\n",
    "            pred,Acc= LSTM(x_train_2,y_train_2,x_test,y_test)\n",
    "            y_pred.insert(y_pred.shape[1],feature_selection[i]+Model_selection[j], pred)\n",
    "        if (j==2):\n",
    "            print(\"The model is: \"+feature_selection[i]+\"+\"+Model_selection[j])\n",
    "            pred,Acc= SVM(x_train,y_train,x_train_2,y_train_2,x_test,y_test)\n",
    "            y_pred.insert(y_pred.shape[1],feature_selection[i]+Model_selection[j], pred)\n",
    "        if (j==3):\n",
    "            print(\"The model is: \"+feature_selection[i]+\"+\"+Model_selection[j])\n",
    "            pred,Acc= MLP(x_train,y_train,x_test,y_test)\n",
    "            y_pred.insert(y_pred.shape[1],feature_selection[i]+Model_selection[j], pred)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [
    "09FqG65S6Spj"
   ],
   "machine_shape": "hm",
   "name": "advanced_random_forest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
